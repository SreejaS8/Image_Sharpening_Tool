{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c0948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_train.py\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from basicsr.archs.restormer_arch import Restormer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413681e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurboDataset(Dataset):\n",
    "    \"\"\"RAM-cached dataset with optimized loading\"\"\"\n",
    "    def __init__(self, blur_dir, sharp_dir, size=128):\n",
    "        self.blur_paths = sorted([\n",
    "            os.path.join(blur_dir, f) \n",
    "            for f in os.listdir(blur_dir) \n",
    "            if f.lower().endswith(('.png','.jpg','.jpeg'))\n",
    "        ])\n",
    "        self.sharp_paths = sorted([\n",
    "            os.path.join(sharp_dir, f) \n",
    "            for f in os.listdir(sharp_dir) \n",
    "            if f.lower().endswith(('.png','.jpg','.jpeg'))\n",
    "        ])\n",
    "        \n",
    "        # Pre-load all images into RAM\n",
    "        print(\"‚ö° Caching images...\")\n",
    "        self.cache = []\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((size, size)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        for b_path, s_path in zip(self.blur_paths, self.sharp_paths):\n",
    "            blur = Image.open(b_path).convert('RGB')\n",
    "            sharp = Image.open(s_path).convert('RGB')\n",
    "            self.cache.append((\n",
    "                self.transform(blur),\n",
    "                self.transform(sharp)\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e236dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __len__(self):\n",
    "        return len(self.cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3967a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __getitem__(self, idx):\n",
    "        return self.cache[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee621b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NanoRestormer(Restormer):\n",
    "    \"\"\"Ultra-light student model\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            dim=16,                  # Reduced capacity\n",
    "            num_blocks=[1,1,1,1],    # Minimal depth\n",
    "            num_refinement_blocks=1,\n",
    "            heads=[1,1,1,1],         # Few attention heads\n",
    "            ffn_expansion_factor=1.5, # Smaller expansion\n",
    "            bias=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b620179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Hardware setup\n",
    "    device = torch.device(\"cpu\")\n",
    "    torch.set_num_threads(os.cpu_count() or 4)\n",
    "    print(f\"üöÄ Training on {device} with {torch.get_num_threads()} threads\")\n",
    "    \n",
    "    # Data - Full 1029 samples\n",
    "    dataset = TurboDataset(\n",
    "        blur_dir=\"C:/Users/Nayana/OneDrive/Desktop/image sharpening kb/dataset/gopro/gopro_deblur/blur/images\",\n",
    "        sharp_dir=\"C:/Users/Nayana/OneDrive/Desktop/image sharpening kb/dataset/gopro/gopro_deblur/sharp/images\",\n",
    "        size=128  # Fixed small size\n",
    "    )\n",
    "    \n",
    "    # Large batch size for CPU efficiency\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=16,  # Increased from 8\n",
    "        shuffle=True,\n",
    "        num_workers=0   # Disabled for RAM caching\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b814f8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Teacher model\n",
    "    teacher = Restormer().eval()\n",
    "    teacher.load_state_dict(torch.load(\n",
    "        \"pretrained_models/motion_deblurring.pth\",\n",
    "        map_location=device\n",
    "    )[\"params\"])\n",
    "    teacher = teacher.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de07dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Tiny student model\n",
    "    student = NanoRestormer().to(device)\n",
    "    optimizer = optim.Adam(student.parameters(), lr=2e-4)  # Higher learning rate\n",
    "    loss_fn = nn.L1Loss()  # Faster than MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7f160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Time tracking\n",
    "    start_time = time.time()\n",
    "    max_duration = 6 * 3600  # 6 hours in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a218c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for epoch in range(50):\n",
    "        epoch_start = time.time()\n",
    "        student.train()\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for blurry, sharp in tqdm(dataloader, desc=f\"Epoch {epoch+1}/50\"):\n",
    "            # Check time remaining\n",
    "            elapsed = time.time() - start_time\n",
    "            if elapsed > max_duration * 0.95:  # Stop before 6 hours\n",
    "                print(\"\\n‚è∞ Approaching 6 hour limit - saving model...\")\n",
    "                torch.save({\"params\": student.state_dict()}, \"student_final.pth\")\n",
    "                print(\"‚úÖ Model saved successfully\")\n",
    "                return\n",
    "            \n",
    "            blurry, sharp = blurry.to(device), sharp.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                teacher_out = teacher(blurry)\n",
    "            \n",
    "            student_out = student(blurry)\n",
    "            loss = loss_fn(student_out, teacher_out)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        remaining = max(0, max_duration - (time.time() - start_time))\n",
    "        epochs_left = min(50 - (epoch+1), int(remaining / epoch_time))\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} | Loss: {epoch_loss/len(dataloader):.4f} | \"\n",
    "              f\"Time: {epoch_time:.1f}s | Est. remaining: {epochs_left} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "    torch.save({\"params\": student.state_dict()}, \"student_final.pth\")\n",
    "    print(\"‚úÖ Full training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a99c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"  # Prevents thread oversubscription\n",
    "    train()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
