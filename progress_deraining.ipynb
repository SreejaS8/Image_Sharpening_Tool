{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a30786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 1/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:51<00:00, 15.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 1 completed | Avg Loss: 0.0737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 2/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:49<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 2 completed | Avg Loss: 0.0520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 3/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:59<00:00, 14.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 3 completed | Avg Loss: 0.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 4/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [02:01<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 4 completed | Avg Loss: 0.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 5/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [02:00<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 5 completed | Avg Loss: 0.0388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 6/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [02:01<00:00, 14.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 6 completed | Avg Loss: 0.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 7/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [02:03<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 7 completed | Avg Loss: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 8/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:58<00:00, 14.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 8 completed | Avg Loss: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 9/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:52<00:00, 15.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 9 completed | Avg Loss: 0.0338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 10/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:48<00:00, 15.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 10 completed | Avg Loss: 0.0329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 11/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:55<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 11 completed | Avg Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 12/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [02:02<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 12 completed | Avg Loss: 0.0316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 13/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [02:01<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 13 completed | Avg Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 14/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [02:01<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 14 completed | Avg Loss: 0.0306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 15/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [02:05<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 15 completed | Avg Loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 16/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [02:01<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 16 completed | Avg Loss: 0.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 17/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [02:01<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 17 completed | Avg Loss: 0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 18/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [02:00<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 18 completed | Avg Loss: 0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 19/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [02:04<00:00, 13.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 19 completed | Avg Loss: 0.0285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 20/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [02:01<00:00, 14.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 20 completed | Avg Loss: 0.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 21/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:49<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 21 completed | Avg Loss: 0.0279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 22/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:50<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 22 completed | Avg Loss: 0.0278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 23/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:51<00:00, 15.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 23 completed | Avg Loss: 0.0276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 24/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:48<00:00, 15.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 24 completed | Avg Loss: 0.0273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 25/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:48<00:00, 15.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 25 completed | Avg Loss: 0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 26/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:58<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 26 completed | Avg Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 27/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:57<00:00, 14.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 27 completed | Avg Loss: 0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 28/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:59<00:00, 14.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 28 completed | Avg Loss: 0.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 29/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:57<00:00, 14.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 29 completed | Avg Loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 30/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:59<00:00, 14.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 30 completed | Avg Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 31/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:59<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 31 completed | Avg Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 32/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [02:01<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 32 completed | Avg Loss: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 33/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:58<00:00, 14.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 33 completed | Avg Loss: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 34/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:59<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 34 completed | Avg Loss: 0.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ§  Training Epoch 35/35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:50<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 35 completed | Avg Loss: 0.0254\n",
      "ğŸ“¦ Model saved to student_kd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Evaluating Student: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1714/1714 [01:37<00:00, 17.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Student SSIM: 0.9078 | PSNR: 30.52 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Residual Block ===\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv2(self.relu(self.conv1(x)))\n",
    "\n",
    "# === Student Model ===\n",
    "class StudentDerain(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        self.middle = nn.Sequential(\n",
    "            ResidualBlock(64), ResidualBlock(64),\n",
    "            ResidualBlock(64), ResidualBlock(64)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 2, stride=2), nn.ReLU(),\n",
    "            nn.Conv2d(32, 3, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# === Dataset ===\n",
    "class DerainDataset(Dataset):\n",
    "    def __init__(self, rainy, sharp_dir, transform):\n",
    "        self.rainy = rainy\n",
    "        self.sharp_dir = sharp_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        rainy_files = sorted(os.listdir(rainy))\n",
    "        sharp_files = sorted(os.listdir(sharp_dir))\n",
    "\n",
    "        self.pairs = []\n",
    "        for b in rainy_files:\n",
    "            base = b.split('_')[0]\n",
    "            sharp_match = next((s for s in sharp_files if s.startswith(base)), None)\n",
    "            if sharp_match:\n",
    "                self.pairs.append((b, sharp_match))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rain_name, sharp_name = self.pairs[idx]\n",
    "        rain = Image.open(os.path.join(self.rainy, rain_name)).convert(\"RGB\")\n",
    "        sharp = Image.open(os.path.join(self.sharp_dir, sharp_name)).convert(\"RGB\")\n",
    "        return self.transform(rain), self.transform(sharp)\n",
    "\n",
    "# === Evaluation ===\n",
    "def evaluate(student, dataloader, device):\n",
    "    student.eval()\n",
    "    s_ssim, s_psnr = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for rain, sharp in tqdm(dataloader, desc=\"ğŸ” Evaluating Student\"):\n",
    "            rain = rain.to(device)\n",
    "            sharp = sharp.to(device)\n",
    "            pred = student(rain)\n",
    "\n",
    "            gt = sharp[0].permute(1, 2, 0).cpu().numpy()\n",
    "            out = pred[0].permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "            gt = np.clip(gt, 0, 1)\n",
    "            out = np.clip(out, 0, 1)\n",
    "\n",
    "            s_ssim += compare_ssim(gt, out, channel_axis=2, data_range=1.0)\n",
    "            s_psnr += compare_psnr(gt, out, data_range=1.0)\n",
    "\n",
    "    total = len(dataloader)\n",
    "    print(f\"\\nğŸ“Š Student SSIM: {s_ssim/total:.4f} | PSNR: {s_psnr/total:.2f} dB\")\n",
    "\n",
    "# === Training ===\n",
    "def train(student, dataloader, device, epochs=35):\n",
    "    student.train()\n",
    "    optimizer = optim.Adam(student.parameters(), lr=1e-4)\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for rain, sharp in tqdm(dataloader, desc=f\"ğŸ§  Training Epoch {epoch+1}/{epochs}\"):\n",
    "            rain, sharp = rain.to(device), sharp.to(device)\n",
    "            pred = student(rain)\n",
    "            loss = criterion(pred, sharp)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"âœ… Epoch {epoch+1} completed | Avg Loss: {avg_loss:.4f}\")\n",
    "    torch.save({'params': student.state_dict()}, \"student_kd.pth\")\n",
    "    print(\"ğŸ“¦ Model saved to student_kd.pth\")\n",
    "\n",
    "# === Run ===\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"ğŸš€ Using device: {device}\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    dataset = DerainDataset(\"Dataset/train/Rain13K/input\", \"Dataset/train/Rain13K/target\", transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "    student = StudentDerain().to(device)\n",
    "    train(student, dataloader, device, epochs=35)\n",
    "    evaluate(student, dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b29a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Using device: cuda\n",
      "ğŸ“¦ Student model parameters: 360835\n",
      "\n",
      "ğŸ” Now evaluating dataset: ğŸ“‚ **Rain100H**\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“· Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:24<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Completed Evaluation: Rain100H (100 images)\n",
      "ğŸ“ Teacher  | SSIM: 0.8498 | PSNR: 25.97 dB\n",
      "ğŸ‘¶ Student  | SSIM: 0.7820 | PSNR: 23.85 dB\n",
      "\n",
      "ğŸ” Now evaluating dataset: ğŸ“‚ **Rain100L**\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“· Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:20<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Completed Evaluation: Rain100L (100 images)\n",
      "ğŸ“ Teacher  | SSIM: 0.9614 | PSNR: 35.66 dB\n",
      "ğŸ‘¶ Student  | SSIM: 0.8805 | PSNR: 28.30 dB\n",
      "\n",
      "ğŸ” Now evaluating dataset: ğŸ“‚ **Test100**\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“· Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:27<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Completed Evaluation: Test100 (98 images)\n",
      "ğŸ“ Teacher  | SSIM: 0.8579 | PSNR: 23.96 dB\n",
      "ğŸ‘¶ Student  | SSIM: 0.8584 | PSNR: 23.82 dB\n",
      "\n",
      "ğŸ” Now evaluating dataset: ğŸ“‚ **Test1200**\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“· Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [03:00<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Completed Evaluation: Test1200 (1200 images)\n",
      "ğŸ“ Teacher  | SSIM: 0.8763 | PSNR: 25.53 dB\n",
      "ğŸ‘¶ Student  | SSIM: 0.9087 | PSNR: 28.18 dB\n",
      "\n",
      "ğŸ” Now evaluating dataset: ğŸ“‚ **Test2800**\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“· Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2800/2800 [04:40<00:00,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Completed Evaluation: Test2800 (2800 images)\n",
      "ğŸ“ Teacher  | SSIM: 0.9255 | PSNR: 29.06 dB\n",
      "ğŸ‘¶ Student  | SSIM: 0.9323 | PSNR: 30.93 dB\n",
      "\n",
      "ğŸ“ŠğŸ“ŠğŸ“Š Overall Average Results Across Datasets ğŸ“ŠğŸ“ŠğŸ“Š\n",
      "ğŸ“ Teacher  | Avg SSIM: 0.8942 | Avg PSNR: 28.03 dB\n",
      "ğŸ‘¶ Student  | Avg SSIM: 0.8724 | Avg PSNR: 27.02 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "import numpy as np\n",
    "\n",
    "# --- Import teacher model architecture ---\n",
    "sys.path.append(os.path.abspath('./Restormer/basicsr/models/archs'))\n",
    "from restormer_arch import Restormer\n",
    "\n",
    "# --- Student Model ---\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv2(self.relu(self.conv1(x)))\n",
    "\n",
    "class StudentDerain(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        self.middle = nn.Sequential(\n",
    "            ResidualBlock(64), ResidualBlock(64),\n",
    "            ResidualBlock(64), ResidualBlock(64)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 2, stride=2), nn.ReLU(),\n",
    "            nn.Conv2d(32, 3, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# --- Dataset ---\n",
    "class DerainDataset(Dataset):\n",
    "    def __init__(self, rainy, sharp_dir, transform):\n",
    "        self.rainy = rainy\n",
    "        self.sharp_dir = sharp_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        rainy_files = sorted(os.listdir(rainy))\n",
    "        sharp_files = sorted(os.listdir(sharp_dir))\n",
    "\n",
    "        self.pairs = []\n",
    "        for b in rainy_files:\n",
    "            base = b.split('_')[0]\n",
    "            sharp_match = next((s for s in sharp_files if s.startswith(base)), None)\n",
    "            if sharp_match:\n",
    "                self.pairs.append((b, sharp_match))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rain_name, sharp_name = self.pairs[idx]\n",
    "        rain_path = os.path.join(self.rainy, rain_name)\n",
    "        sharp_path = os.path.join(self.sharp_dir, sharp_name)\n",
    "        rain = Image.open(rain_path).convert(\"RGB\")\n",
    "        sharp = Image.open(sharp_path).convert(\"RGB\")\n",
    "        return self.transform(rain), self.transform(sharp)\n",
    "\n",
    "# --- Evaluation on a single dataset ---\n",
    "def evaluate_on_folder(student, teacher, rainy, sharp_dir, transform, device, dataset_name):\n",
    "    dataset = DerainDataset(rainy, sharp_dir, transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    teacher.eval()\n",
    "    student.eval()\n",
    "\n",
    "    teacher_ssim_total = student_ssim_total = 0\n",
    "    teacher_psnr_total = student_psnr_total = 0\n",
    "    total_images = len(dataset)\n",
    "\n",
    "    print(f\"\\nğŸ” Now evaluating dataset: ğŸ“‚ **{dataset_name}**\\n{'-'*60}\")\n",
    "    for rain, sharp in tqdm(dataloader, desc=f\"ğŸ“· Images\", total=total_images):\n",
    "        rain = rain.to(device)\n",
    "        sharp = sharp.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_out = teacher(rain)\n",
    "            student_out = student(rain)\n",
    "\n",
    "        t_img = teacher_out.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "        s_img = student_out.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "        gt_img = sharp.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "        t_img = np.clip(t_img, 0, 1)\n",
    "        s_img = np.clip(s_img, 0, 1)\n",
    "        gt_img = np.clip(gt_img, 0, 1)\n",
    "\n",
    "        teacher_ssim_total += compare_ssim(gt_img, t_img, channel_axis=2, data_range=1.0)\n",
    "        student_ssim_total += compare_ssim(gt_img, s_img, channel_axis=2, data_range=1.0)\n",
    "        teacher_psnr_total += compare_psnr(gt_img, t_img, data_range=1.0)\n",
    "        student_psnr_total += compare_psnr(gt_img, s_img, data_range=1.0)\n",
    "\n",
    "    teacher_ssim_avg = teacher_ssim_total / total_images\n",
    "    student_ssim_avg = student_ssim_total / total_images\n",
    "    teacher_psnr_avg = teacher_psnr_total / total_images\n",
    "    student_psnr_avg = student_psnr_total / total_images\n",
    "\n",
    "    print(f\"\\nğŸ“ Completed Evaluation: {dataset_name} ({total_images} images)\")\n",
    "    print(f\"ğŸ“ Teacher  | SSIM: {teacher_ssim_avg:.4f} | PSNR: {teacher_psnr_avg:.2f} dB\")\n",
    "    print(f\"ğŸ‘¶ Student  | SSIM: {student_ssim_avg:.4f} | PSNR: {student_psnr_avg:.2f} dB\")\n",
    "\n",
    "    return teacher_ssim_avg, teacher_psnr_avg, student_ssim_avg, student_psnr_avg\n",
    "\n",
    "# --- Main evaluation loop ---\n",
    "def evaluate_all(student_ckpt, teacher_ckpt, test_root):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"ğŸš€ Using device: {device}\")\n",
    "\n",
    "    # Load teacher\n",
    "    teacher = Restormer(\n",
    "        inp_channels=3, out_channels=3, dim=48,\n",
    "        num_blocks=[4, 6, 6, 8], num_refinement_blocks=4,\n",
    "        heads=[1, 2, 4, 8], ffn_expansion_factor=2.66,\n",
    "        bias=False, LayerNorm_type='WithBias', dual_pixel_task=False\n",
    "    ).to(device)\n",
    "    teacher.load_state_dict(torch.load(teacher_ckpt, map_location=device)['params'])\n",
    "\n",
    "    # Load student\n",
    "    student = StudentDerain().to(device)\n",
    "    ckpt = torch.load(student_ckpt, map_location=device)\n",
    "    corrected_state_dict = {\n",
    "        k.replace(\"params.\", \"\"): v for k, v in ckpt['params'].items()\n",
    "    }\n",
    "    student.load_state_dict(corrected_state_dict)\n",
    "    print(f\"ğŸ“¦ Student model parameters: {sum(p.numel() for p in student.parameters())}\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Accumulate metrics\n",
    "    total_datasets = 0\n",
    "    all_teacher_ssim = all_teacher_psnr = 0\n",
    "    all_student_ssim = all_student_psnr = 0\n",
    "\n",
    "    for subfolder in sorted(os.listdir(test_root)):\n",
    "        rainy = os.path.join(test_root, subfolder, \"input\")\n",
    "        sharp_dir = os.path.join(test_root, subfolder, \"target\")\n",
    "\n",
    "        if not os.path.isdir(rainy) or not os.path.isdir(sharp_dir):\n",
    "            print(f\"âš ï¸ Skipping {subfolder}: missing input/target folders.\")\n",
    "            continue\n",
    "\n",
    "        t_ssim, t_psnr, s_ssim, s_psnr = evaluate_on_folder(\n",
    "            student, teacher, rainy, sharp_dir, transform, device, subfolder\n",
    "        )\n",
    "\n",
    "        all_teacher_ssim += t_ssim\n",
    "        all_teacher_psnr += t_psnr\n",
    "        all_student_ssim += s_ssim\n",
    "        all_student_psnr += s_psnr\n",
    "        total_datasets += 1\n",
    "\n",
    "    if total_datasets > 0:\n",
    "        print(\"\\nğŸ“ŠğŸ“ŠğŸ“Š Overall Average Results Across Datasets ğŸ“ŠğŸ“ŠğŸ“Š\")\n",
    "        print(f\"ğŸ“ Teacher  | Avg SSIM: {all_teacher_ssim/total_datasets:.4f} | Avg PSNR: {all_teacher_psnr/total_datasets:.2f} dB\")\n",
    "        print(f\"ğŸ‘¶ Student  | Avg SSIM: {all_student_ssim/total_datasets:.4f} | Avg PSNR: {all_student_psnr/total_datasets:.2f} dB\")\n",
    "    else:\n",
    "        print(\"âŒ No valid datasets found to evaluate.\")\n",
    "\n",
    "# --- Entry point ---\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_all(\n",
    "        student_ckpt=\"student_kd.pth\",\n",
    "        teacher_ckpt=\"deraining.pth\",\n",
    "        test_root=\"Dataset/test\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fbc548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intel_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
